{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c58f7ed1",
   "metadata": {},
   "source": [
    "# Titanic: Enhanced Modeling & Feature Engineering\n",
    "\n",
    "This notebook adds:\n",
    "- Rich feature engineering (titles, decks, family features, age/fare buckets, traveling alone, etc.).\n",
    "- Multiple model comparison with `GridSearchCV` and stratified cross-validation.\n",
    "- A leaderboard of models and tuned hyperparameters.\n",
    "- Optional `submission.csv` if `test.csv` is present.\n",
    "\n",
    "> Place `train.csv` (and optionally `test.csv`) next to this notebook or in `/mnt/data/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3281d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core setup\n",
    "import os, re, math, warnings, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd6494cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv('C:/Datasets/train.csv')\n",
    "test_df = pd.read_csv('C:/Datasets/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "529c081d-fdc5-4335-8574-e4024ef01914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51954945-d77c-4503-9170-efffcfbfecc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9013fa0c-ee92-4ac4-9728-28a0c03acab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d39a9371-9b9a-4621-ad73-e8c969dd3440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(28.0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e341d3c-f579-4506-9cd2-ae805f07c968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f11256c-382e-4fed-89da-30fe3663de1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f7c38ca-a6f0-4260-b4f2-a9d0a025e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "male      577\n",
       "female    314\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95d85f9a-c9bb-45b7-b3e6-a819af44a9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9cbf0",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We create:\n",
    "- `Relatives = SibSp + Parch` and `IsAlone`.\n",
    "- `FamilySize = Relatives + 1` (including the passenger).\n",
    "- Extract `Title` from `Name` and group rare titles.\n",
    "- `Deck` from the first letter of `Cabin`.\n",
    "- `AgeBucket` via fixed bins; `FareBucket` via quantiles.\n",
    "- Keep `Pclass`, `Sex`, `Embarked` as categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34b7dc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Relatives</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>TitleRaw</th>\n",
       "      <th>Title</th>\n",
       "      <th>Deck</th>\n",
       "      <th>AgeBucket</th>\n",
       "      <th>FareBucket</th>\n",
       "      <th>TravelType</th>\n",
       "      <th>SibSpParchSum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>YoungAdult</td>\n",
       "      <td>(-0.001, 7.91]</td>\n",
       "      <td>WithFamily</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>WithFamily</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>YoungAdult</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>Alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>C</td>\n",
       "      <td>Adult</td>\n",
       "      <td>(31.0, 512.329]</td>\n",
       "      <td>WithFamily</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Adult</td>\n",
       "      <td>(7.91, 14.454]</td>\n",
       "      <td>Alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare  ... Relatives FamilySize  IsAlone  \\\n",
       "0      0         A/5 21171   7.2500  ...         1          2        0   \n",
       "1      0          PC 17599  71.2833  ...         1          2        0   \n",
       "2      0  STON/O2. 3101282   7.9250  ...         0          1        1   \n",
       "3      0            113803  53.1000  ...         1          2        0   \n",
       "4      0            373450   8.0500  ...         0          1        1   \n",
       "\n",
       "   TitleRaw  Title     Deck   AgeBucket       FareBucket  TravelType  \\\n",
       "0        Mr     Mr  Unknown  YoungAdult   (-0.001, 7.91]  WithFamily   \n",
       "1       Mrs    Mrs        C       Adult  (31.0, 512.329]  WithFamily   \n",
       "2      Miss   Miss  Unknown  YoungAdult   (7.91, 14.454]       Alone   \n",
       "3       Mrs    Mrs        C       Adult  (31.0, 512.329]  WithFamily   \n",
       "4        Mr     Mr  Unknown       Adult   (7.91, 14.454]       Alone   \n",
       "\n",
       "  SibSpParchSum  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineering helpers\n",
    "def extract_title(name: str) -> str:\n",
    "    if pd.isna(name):\n",
    "        return \"Unknown\"\n",
    "    m = re.search(r\",\\s*([^\\.]+)\\.\", name)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    return \"Unknown\"\n",
    "\n",
    "def map_title(title: str) -> str:\n",
    "    # Group rare titles\n",
    "    title = title.strip()\n",
    "    common = {\"Mr\",\"Mrs\",\"Miss\",\"Master\"}\n",
    "    if title in common:\n",
    "        return title\n",
    "    # Map similar/rare titles\n",
    "    mapping = {\n",
    "        \"Mlle\":\"Miss\",\"Ms\":\"Miss\",\"Mme\":\"Mrs\",\n",
    "        \"Lady\":\"Royalty\",\"Countess\":\"Royalty\",\"Sir\":\"Royalty\",\"Don\":\"Royalty\",\"Dona\":\"Royalty\",\"Jonkheer\":\"Royalty\",\n",
    "        \"Dr\":\"Officer\",\"Rev\":\"Officer\",\"Col\":\"Officer\",\"Major\":\"Officer\",\"Capt\":\"Officer\"\n",
    "    }\n",
    "    return mapping.get(title, \"Rare\")\n",
    "\n",
    "def first_letter_or_unknown(x):\n",
    "    if isinstance(x, str) and len(x)>0:\n",
    "        return x[0].upper()\n",
    "    return \"Unknown\"\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    # Relatives & alone\n",
    "    out[\"Relatives\"] = out[\"SibSp\"].fillna(0) + out[\"Parch\"].fillna(0)\n",
    "    out[\"FamilySize\"] = out[\"Relatives\"] + 1\n",
    "    out[\"IsAlone\"] = (out[\"Relatives\"] == 0).astype(int)\n",
    "\n",
    "    # Title\n",
    "    out[\"TitleRaw\"] = out[\"Name\"].apply(extract_title)\n",
    "    out[\"Title\"] = out[\"TitleRaw\"].apply(map_title)\n",
    "\n",
    "    # Deck from Cabin\n",
    "    out[\"Deck\"] = out[\"Cabin\"].apply(first_letter_or_unknown)\n",
    "\n",
    "    # Age bucket (fixed sensible bins)\n",
    "    # Infant, Child, Teen, YoungAdult, Adult, MidAge, Senior\n",
    "    age_bins = [0, 2, 12, 18, 30, 45, 60, np.inf]\n",
    "    age_labels = [\"Infant\",\"Child\",\"Teen\",\"YoungAdult\",\"Adult\",\"MidAge\",\"Senior\"]\n",
    "    out[\"AgeBucket\"] = pd.cut(out[\"Age\"], bins=age_bins, labels=age_labels)\n",
    "\n",
    "    # Fare bucket (quantiles)\n",
    "    out[\"FareBucket\"] = pd.qcut(out[\"Fare\"], q=4, duplicates=\"drop\")\n",
    "\n",
    "    # Traveling alone category for emphasis\n",
    "    out[\"TravelType\"] = np.where(out[\"IsAlone\"]==1, \"Alone\", \"WithFamily\")\n",
    "\n",
    "    # Replace SibSp & Parch with sum if desired (keep originals too for comparison)\n",
    "    out[\"SibSpParchSum\"] = out[\"Relatives\"]\n",
    "\n",
    "    # Columns used downstream\n",
    "    return out\n",
    "\n",
    "fe_train = build_features(train_df)\n",
    "fe_test  = build_features(test_df) if test_df is not None else None\n",
    "\n",
    "fe_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68013ce7-c439-4fc4-a9f7-5110e9816f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived       1.000000\n",
       "Fare           0.257307\n",
       "Parch          0.081629\n",
       "PassengerId   -0.005007\n",
       "SibSp         -0.035322\n",
       "Age           -0.077221\n",
       "Pclass        -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = train_df.corr(numeric_only=True)\n",
    "\n",
    "corr_matrix['Survived'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5a991",
   "metadata": {},
   "source": [
    "## Preprocessing & Column Transformer\n",
    "- Numeric features imputed (median) + scaled (for certain models).\n",
    "- Categorical features imputed (most frequent) + one-hot encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "341b4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "target = \"Survived\"\n",
    "numeric_features = [\"Age\",\"Fare\",\"FamilySize\",\"Relatives\",\"SibSpParchSum\"]\n",
    "categorical_features = [\n",
    "    \"Pclass\",\"Sex\",\"Embarked\",\"Title\",\"Deck\",\"AgeBucket\",\"FareBucket\",\"TravelType\"\n",
    "]\n",
    "\n",
    "# Preprocessors\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False))  # sparse-safe\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X = fe_train[numeric_features + categorical_features]\n",
    "y = fe_train[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3c424",
   "metadata": {},
   "source": [
    "## Models & Hyperparameter Grids\n",
    "\n",
    "We compare several classifiers with tuned grids using `GridSearchCV` and 5-fold `StratifiedKFold`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f40014b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LogReg: GridSearchCV ===\n",
      "Best CV accuracy: 0.8294\n",
      "Best params: {'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n",
      "\n",
      "=== SVC: GridSearchCV ===\n",
      "Best CV accuracy: 0.8373\n",
      "Best params: {'clf__C': 2, 'clf__gamma': 'auto', 'clf__kernel': 'rbf'}\n",
      "\n",
      "=== KNN: GridSearchCV ===\n",
      "Best CV accuracy: 0.8440\n",
      "Best params: {'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV_Accuracy</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.844009</td>\n",
       "      <td>{'clf__n_neighbors': 7, 'clf__p': 1, 'clf__wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837254</td>\n",
       "      <td>{'clf__C': 2, 'clf__gamma': 'auto', 'clf__kern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.829402</td>\n",
       "      <td>{'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  CV_Accuracy                                        Best_Params\n",
       "0     KNN     0.844009  {'clf__n_neighbors': 7, 'clf__p': 1, 'clf__wei...\n",
       "1     SVC     0.837254  {'clf__C': 2, 'clf__gamma': 'auto', 'clf__kern...\n",
       "2  LogReg     0.829402  {'clf__C': 1.0, 'clf__penalty': 'l2', 'clf__so..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define models and parameter grids\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "pipelines_and_grids = []\n",
    "\n",
    "# Logistic Regression\n",
    "pipelines_and_grids.append((\n",
    "    \"LogReg\",\n",
    "    Pipeline([(\"prep\", preprocessor),\n",
    "              (\"clf\", LogisticRegression(max_iter=500, random_state=RANDOM_STATE))]),\n",
    "    {\n",
    "        \"clf__C\":[0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "        \"clf__penalty\":[\"l2\"],\n",
    "        \"clf__solver\":[\"lbfgs\",\"liblinear\"]\n",
    "    }\n",
    "))\n",
    "\n",
    "# SVC\n",
    "pipelines_and_grids.append((\n",
    "    \"SVC\",\n",
    "    Pipeline([(\"prep\", preprocessor),\n",
    "              (\"clf\", SVC(random_state=RANDOM_STATE))]),\n",
    "    {\n",
    "        \"clf__C\":[0.5, 1, 2, 5],\n",
    "        \"clf__kernel\":[\"rbf\",\"linear\"],\n",
    "        \"clf__gamma\":[\"scale\",\"auto\"]\n",
    "    }\n",
    "))\n",
    "\n",
    "# KNN\n",
    "pipelines_and_grids.append((\n",
    "    \"KNN\",\n",
    "    Pipeline([(\"prep\", preprocessor),\n",
    "              (\"clf\", KNeighborsClassifier())]),\n",
    "    {\n",
    "        \"clf__n_neighbors\":[3,5,7,9,11],\n",
    "        \"clf__weights\":[\"uniform\",\"distance\"],\n",
    "        \"clf__p\":[1,2]\n",
    "    }\n",
    "))\n",
    "\n",
    "\n",
    "\n",
    "results = []\n",
    "best_estimators = {}\n",
    "\n",
    "for name, pipe, grid in pipelines_and_grids:\n",
    "    print(f\"=== {name}: GridSearchCV ===\")\n",
    "    gs = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=grid,\n",
    "        scoring=\"accuracy\",\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    gs.fit(X, y)\n",
    "    best_score = gs.best_score_\n",
    "    best_params = gs.best_params_\n",
    "    results.append((name, best_score, best_params))\n",
    "    best_estimators[name] = gs.best_estimator_\n",
    "    print(f\"Best CV accuracy: {best_score:.4f}\")\n",
    "    print(f\"Best params: {best_params}\\n\")\n",
    "\n",
    "leaderboard = pd.DataFrame(results, columns=[\"Model\",\"CV_Accuracy\",\"Best_Params\"]).sort_values(\"CV_Accuracy\", ascending=False).reset_index(drop=True)\n",
    "leaderboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988f45a",
   "metadata": {},
   "source": [
    "## Fit Best Model & Evaluate (Train CV)\n",
    "We refit the top model (already refit by GridSearch) and keep it for export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3df1a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top model: KNN\n",
      "Params: {'memory': None, 'steps': [('prep', ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('scaler',\n",
      "                                                  StandardScaler(with_mean=False))]),\n",
      "                                 ['Age', 'Fare', 'FamilySize', 'Relatives',\n",
      "                                  'SibSpParchSum']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('onehot',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 ['Pclass', 'Sex', 'Embarked', 'Title', 'Deck',\n",
      "                                  'AgeBucket', 'FareBucket', 'TravelType'])])), ('clf', KNeighborsClassifier(n_neighbors=7, p=1))], 'transform_input': None, 'verbose': False, 'prep': ColumnTransformer(transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('scaler',\n",
      "                                                  StandardScaler(with_mean=False))]),\n",
      "                                 ['Age', 'Fare', 'FamilySize', 'Relatives',\n",
      "                                  'SibSpParchSum']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('onehot',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 ['Pclass', 'Sex', 'Embarked', 'Title', 'Deck',\n",
      "                                  'AgeBucket', 'FareBucket', 'TravelType'])]), 'clf': KNeighborsClassifier(n_neighbors=7, p=1), 'prep__force_int_remainder_cols': 'deprecated', 'prep__n_jobs': None, 'prep__remainder': 'drop', 'prep__sparse_threshold': 0.3, 'prep__transformer_weights': None, 'prep__transformers': [('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
      "                ('scaler', StandardScaler(with_mean=False))]), ['Age', 'Fare', 'FamilySize', 'Relatives', 'SibSpParchSum']), ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('onehot', OneHotEncoder(handle_unknown='ignore'))]), ['Pclass', 'Sex', 'Embarked', 'Title', 'Deck', 'AgeBucket', 'FareBucket', 'TravelType'])], 'prep__verbose': False, 'prep__verbose_feature_names_out': True, 'prep__num': Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
      "                ('scaler', StandardScaler(with_mean=False))]), 'prep__cat': Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "                ('onehot', OneHotEncoder(handle_unknown='ignore'))]), 'prep__num__memory': None, 'prep__num__steps': [('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler(with_mean=False))], 'prep__num__transform_input': None, 'prep__num__verbose': False, 'prep__num__imputer': SimpleImputer(strategy='median'), 'prep__num__scaler': StandardScaler(with_mean=False), 'prep__num__imputer__add_indicator': False, 'prep__num__imputer__copy': True, 'prep__num__imputer__fill_value': None, 'prep__num__imputer__keep_empty_features': False, 'prep__num__imputer__missing_values': nan, 'prep__num__imputer__strategy': 'median', 'prep__num__scaler__copy': True, 'prep__num__scaler__with_mean': False, 'prep__num__scaler__with_std': True, 'prep__cat__memory': None, 'prep__cat__steps': [('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))], 'prep__cat__transform_input': None, 'prep__cat__verbose': False, 'prep__cat__imputer': SimpleImputer(strategy='most_frequent'), 'prep__cat__onehot': OneHotEncoder(handle_unknown='ignore'), 'prep__cat__imputer__add_indicator': False, 'prep__cat__imputer__copy': True, 'prep__cat__imputer__fill_value': None, 'prep__cat__imputer__keep_empty_features': False, 'prep__cat__imputer__missing_values': nan, 'prep__cat__imputer__strategy': 'most_frequent', 'prep__cat__onehot__categories': 'auto', 'prep__cat__onehot__drop': None, 'prep__cat__onehot__dtype': <class 'numpy.float64'>, 'prep__cat__onehot__feature_name_combiner': 'concat', 'prep__cat__onehot__handle_unknown': 'ignore', 'prep__cat__onehot__max_categories': None, 'prep__cat__onehot__min_frequency': None, 'prep__cat__onehot__sparse_output': True, 'clf__algorithm': 'auto', 'clf__leaf_size': 30, 'clf__metric': 'minkowski', 'clf__metric_params': None, 'clf__n_jobs': None, 'clf__n_neighbors': 7, 'clf__p': 1, 'clf__weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# Select the top model\n",
    "top_row = leaderboard.iloc[0]\n",
    "top_model_name = top_row[\"Model\"]\n",
    "top_model = best_estimators[top_model_name]\n",
    "\n",
    "print(\"Top model:\", top_model_name)\n",
    "print(\"Params:\", top_model.get_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd603045",
   "metadata": {},
   "source": [
    "## Optional: Create `submission.csv`\n",
    "If `test.csv` is available, we will produce a Kaggle-style submission with `PassengerId` and `Survived`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f7f2c82",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 42 features, but ColumnTransformer is expecting 13 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m test_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      2\u001b[39m     X_test = preprocessor.fit_transform(fe_test[numeric_features + categorical_features])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     preds = \u001b[43mtop_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     submission = pd.DataFrame({\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassengerId\u001b[39m\u001b[33m\"\u001b[39m: test_df[\u001b[33m\"\u001b[39m\u001b[33mPassengerId\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSurvived\u001b[39m\u001b[33m\"\u001b[39m: preds.astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      7\u001b[39m     })\n\u001b[32m      8\u001b[39m     submission_path = \u001b[33m\"\u001b[39m\u001b[33mC:/Datasets/artifacts/submission4.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:788\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict(Xt, **params)\n\u001b[32m    791\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1089\u001b[39m, in \u001b[36mColumnTransformer.transform\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m   1085\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1087\u001b[39m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[32m   1088\u001b[39m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[32m   1092\u001b[39m     routed_params = process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2840\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2842\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 42 features, but ColumnTransformer is expecting 13 features as input."
     ]
    }
   ],
   "source": [
    "if test_df is not None:\n",
    "    X_test = preprocessor.fit_transform(fe_test[numeric_features + categorical_features])\n",
    "    preds = top_model.predict(X_test)\n",
    "    submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": preds.astype(int)\n",
    "    })\n",
    "    submission_path = \"C:/Datasets/artifacts/submission4.csv\"\n",
    "    submission.to_csv(submission_path, index=False)\n",
    "    print(f\"Created submission at {submission_path}\")\n",
    "else:\n",
    "    print(\"test.csv not found. Skipping submission generation.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba4411-f864-4403-8fcc-8a2d7794e199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
